# Setup of Globus Flows and Compute Functions

This directory contains scripts to setup the **Globus Flow**, create **Adapters**
that can be imported in the webapplication. It also contains scripts to test the
endpoints and compute functions.

[[_TOC_]]

---

## 1. Overview

- **Globus Flows**: A Globus Flow consists of multiple stages. In our case, we
  reuse the same flow `compute_with_check_flow` for all compute functions.
  The flow stages are:

  - **Setup**: "Action" (compute) stage that calls the `entry_point_function`. The
    setup function resolves the endpoint and function UUID for the actual
    compute function. This way, we can hide the UUID information from the user
  - **SetupCheck**: This "Choice" stage acts as an if statement and checks if
    the setup function returned successfully
  - **SetupFail**: If the setup function failed, this "Fail" stage will cause
    the flow to abort
  - **SetupSucceed**: If the setup function succeeded, this "Pass" stage will
    continue the execution of the flow
  - **Compute**: "Action" (compute) stage that executes the actual compute
    function. Flow inputs are passed as parameters to the function
  - **ComputeCheck**: THis "Choice" stage acts as an if statement and checks if
    the compute function returned successfully
  - **ComputeFail**: If the compute function failed, this "Fail" stage will
    cause the flow to abort
  - **ComputeSucceed**: If the compute function succeeded, this "Pass" stage
    will do nothing and the flow ends successfully here

- **Flow Adapters**: Flow adapters map a functionality (==compute function) to
  the Globus Flow, and are used by the web application (either django, or sveltekit).
  They contain:
  - name of the compute endpoint and function to be used
  - input schema for the the compute function (used to build the input form and
    as validation of inputs)
  - information on where the results can be found (Globus collection UUID and path,
    preview URL)

The `setup-flows` script automates the registration of compute functions and
flows with Globus, and formats the flow adapters so that they can be imported
into the web application.

---

## 2. Running

You can run the scripts on your local machine or any other place.

### 2.1. Prerequisites

The Python library uses [poetry](https://python-poetry.org) to manage
dependencies. If not already installed, follow the
[documentation](https://python-poetry.org/docs) to set up poetry on the system.

It is recommended to change the default location of the virtual environments
generated by poetry to the project folder (`./.venv` instead of
`~/.local`) by running

```bash
    # this will create virtual environments in the project directory (.venv/)
    # instead of the users home directory
    poetry config virtualenvs.in-project true
```

If you've installed poetry within a `conda` environment, you may need to install the [poetry-conda](https://pypi.org/project/poetry-conda/) plugin for the above command to work.


### 2.2 Setup

1.  If not yet done, create a new **native** Globus App on the [Globus Developer
    Settings page](https://app.globus.org/settings/developers) ("Register a
    service account or application credential for automation").

2.  Create a new file with the name `.env` in this folder (`flows`)
    and add the CLIENT_ID you received from the Globus application registration:

    ```bash
    GLOBUS_CLIENT_ID=<CLIENT_ID>
    ```

3.  Install the python library: Within `flows/` (the folder where this
    README.md is located), the following command will install all required
    dependencies:

    ```bash
    poetry install
    ```

    If `virtualenvs.in-project` was set (above), then the virtual environment
    will be created locally in `.venv`. It can be activated either by
    `source .venv/bin/activate` or `poetry shell`.

### 2.3 Registering Flows and creating Adapters

After activating the virtual environment, a new executable should be in your
path, `setup-flows`. Running it will add the flows defined in this repository
to your Globus Account.

```bash
setup-flows <output_folder>
```

The script will generate `.json` templates for the flow adapters that you can
then import into the web application.

To create adapters compatible with the Django backend, add `--django-adapter-format`
to the command.



### 2.4 Testing the Infrastructure

There are several scripts to test the compute-portal infrastructure:

####  2.4.1 Test "Compute" Endpoint Status

The `check-system` script checks if all required endpoints are
registered and online. It will also query the "allowed_functions" whitelist
and make sure that the correct functions are registered.

```bash
check-system
```

#### 2.4.2 Test "Entrypoint" Endpoint Status

The `check-entrypoint` script checks if the entry point endpoint is
registered and online, and if the correct function is in the whitelist. It then
calls the entry-point function with all combinations of "functionality" and
"datasets" that are registered in the adapters.

```bash
check-entrypoint
```

#### 2.4.3 Test "Compute Functions"

TODO: finish



